# System/default
import sys
import os

# Arguments
import argparse
import codecs


from resemblyzer import preprocess_wav, VoiceEncoder
from demo_utils import *
from pathlib import Path
from tqdm import tqdm
import numpy as np


# DEMO 05: In this demo we'll show how we can achieve a modest form of fake speech detection with 
# Resemblyzer. This method assumes you have some reference audio for the target speaker that you 
# know is real, so it is not a universal fake speech detector on its own.
# In the audio data directory we have 18 segments of Donald Trump. 12 are real and extracted from
# actual speeches, while the remaining 6 others are fake and generated by various users on 
# youtube, with a high discrepancy of voice cloning quality and naturalness achieved. We will 
# take 6 segments of real speech as ground truth reference and compare those against the 12 
# remaining. Those segments are selected at random, so will run into different results every time
# you run the script, but they should be more or less consistent.
# Using the voice of Donald Trump is merely a matter of convenience, as several fake speeches 
# with his voice were already put up on youtube. This choice was not politically motivated.

# Two list as arguments real/ fake list

parser = argparse.ArgumentParser(description="")

# Add options
parser.add_argument("-l", "--log_file", default=None, help="Logger file")
parser.add_argument("-v", "--verbosity", action="count", default=0, help="increase output verbosity")
parser.add_argument("--realConfig",dest='real_config_name',type=str, help="increase output verbosity")
parser.add_argument("--fakeConfig",dest='fake_config_name',type=str, help="increase output verbosity")
# Add arguments
parser.add_argument("real_files")
parser.add_argument("conv_files")

args = parser.parse_args()


## Load and preprocess the audio
real_files=args.real_files
conv_files=args.conv_files
real_config_name=args.real_config_name
fake_config_name=args.fake_config_name	

import pandas as pd

#real
real_df=pd.read_csv(real_files)
real_df['speaker']=[os.path.basename(rf).split('_')[0].strip()  for rf in real_df['sound'].to_list()]
real_df['label']=[real_config_name for _ in real_df['sound'].to_list()]

real_df['names']=[os.path.basename(fname).split('.')[0] for fname in real_df['sound'].to_list()]



# fake
conv_df=pd.read_csv(conv_files)
conv_df['speaker']=[os.path.basename(cf).split('_')[0].strip()  for cf in conv_df['sound'].to_list()]
conv_df['label']=[fake_config_name for _ in conv_df['sound'].to_list()]

conv_df['names']=[os.path.basename(fname).split('.')[0] for fname in conv_df['sound'].to_list()]


grouped_by_speaker= real_df.groupby("speaker")
encoder = VoiceEncoder()


result={'target_speaker':[],'source_speaker':[]  ,'config_aa':[], 'config_bb':[] }


for  speaker_grp in  grouped_by_speaker:
	speaker_wavs={}

	
	real_speaker,real_data=speaker_grp
	conv_data=conv_df.iloc[real_data.index]
	

	
	real_wav_fpaths=real_data["sound"].to_list()
	speaker_wavs[real_config_name] = [preprocess_wav(wav_fpath) for wav_fpath in \
					tqdm(real_wav_fpaths, "Preprocessing wavs", len(real_wav_fpaths), unit=" utterances")]



	fake_wav_fpaths=conv_data["sound"].to_list()
	speaker_wavs[fake_config_name] = [preprocess_wav(wav_fpath) for wav_fpath in \
					tqdm(fake_wav_fpaths, "Preprocessing wavs", len(fake_wav_fpaths), unit=" utterances")]


	spk_embeds_a = np.array([encoder.embed_speaker(wavs[:len(wavs) // 2]) \
	                         for wavs in speaker_wavs.values()])
	spk_embeds_b = np.array([encoder.embed_speaker(wavs[len(wavs) // 2:]) \
	                         for wavs in speaker_wavs.values()])


	spk_sim_matrix = np.inner(spk_embeds_a, spk_embeds_b)
	

	labels_a = ["{}_{}".format(real_speaker,i) for i in speaker_wavs.keys()]
	labels_b = ["{}_{}".format(real_speaker,i) for i in speaker_wavs.keys()]
	df_spkear=pd.DataFrame(data=spk_sim_matrix,index=labels_a,columns=labels_b)
	print(df_spkear)

	



		



# print(labels_a,labels_b)
	# speaker_wavs = {speaker: list(map(preprocess_wav, wav_fpaths)) for speaker, wav_fpaths in
                # groupby(tqdm(wav_fpaths, "Preprocessing wavs", len(wav_fpaths), unit="wavs"), 
                        # lambda wav_fpath: wav_fpath.parent.stem)}